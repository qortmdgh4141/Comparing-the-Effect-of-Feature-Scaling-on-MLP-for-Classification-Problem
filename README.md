# ğŸ“‰  Comparing the Effect of Feature Scaling on MLP for Classification Problem
<br/>
  
### 1. &nbsp; Research Objective <br/><br/>

- _The objective of this study is to construct and train an MLP classification model using the "Wine Recognition Dataset" from the UCI Machine Learning Repository, which includes outliers. To achieve this, I will experiment with two feature scaling techniques, normalization and standardization, to determine which one has a more positive impact on the performance of the model._ <br/>

- _Generally, it is known that normalization technique performs better than standardization technique in improving the performance of a model when dealing with datasets that contain outliers. However, for datasets with outliers removed, a normalization technique may improve the performance of the model, or a standardization technique may improve the performance of the model, depending on a variety of factors, including the structure of the model and the characteristics of the dataset._ <br/>

- _Based on this information, I conducted the following experiment:_  <br/>

  - _First, I performed outlier detection and removal using the Interquartile Range (IQR) method on the "Wine Dataset."_ <br/>
  
  - _Then, I applied normalization and standardization techniques to the dataset with the outliers removed._ <br/>
  
  - _Finally, I used the two transformed datasets to train MLP models with the same architecture, respectively, and compared the performance of the models._ <br/>
  
- _Through this experiment, I was able to understand the impact of outlier removal and feature scaling techniques on model performance from different perspectives, and I expect that this information can be utilized in future research and practical applications._ <br/><br/><br/> 

### 2. &nbsp; Key Components of the Neural Network Model and Experimental Settings  <br/><br/>

- _Dense Layer_ <br/>

  - _Number of nodes: (256 or 3)._ <br/>

  - _The dense layer is a traditional neural network layer that connects all inputs and outputs. It learns abstract features and outputs probability distribution for various classes._<br/><br/>
  
- _Dropout Layer_ <br/>

  - _The dropout layer is one of the regularization techniques used to reduce overfitting during the neural network training process._ <br/>

  - _Dropout randomly deactivates some units (neurons) of the neural network during training, preventing the model from relying too heavily on specific units and improving generalization capability._<br/><br/>

- _Activation function for hidden layers : ReLU Function_ <br/>

  - _The ReLU function is a non-linear function that outputs 0 for negative input values and keeps the output as is for positive input values._ <br/>

  - _To alleviate the issue of gradient vanishing caused by weight initialization when using ReLU activation function, the weights of the hidden layers were initialized using He initialization._<br/><br/>

- _Activation function for the output layer : Softmax Function_ <br/>

  - _The softmax function is commonly used as the activation function for the output layer in multi-class classification problems._ <br/>

  - _The softmax function normalizes the input values to calculate the probability of belonging to each class, and the sum of probabilities for all classes is 1._<br/><br/>

- _Optimization Algorithm : Adam (Adaptive Moment Estimation)_ <br/>

  - _The Adam optimization algorithm, which combines the advantages of Momentum, which adjusts the learning rate considering the direction of gradients, and RMSProp, which adjusts the learning rate considering the magnitude of gradients, was used._ <br/>

  - _The softmax function normalizes the input values to calculate the probability of belonging to each class, and the sum of probabilities for all classes is 1._<br/><br/>

- _Loss Function : Cross-Entropy Loss Function_ <br/>

  - _When using the softmax function in the output layer, the cross-entropy loss function is commonly used as the loss function._ <br/>

  - _The cross-entropy loss function calculates the error only for the classes corresponding to the actual target values and updates the model in the direction of minimizing the error._<br/><br/>

- _Evaluation Metric : Accuracy_ <br/>

  - _Accuracy is one of the evaluation metrics used to assess the performance of a classification model._ <br/>

  - _Accuracy considers the prediction as correct if it matches the actual target class and calculates it by dividing it by the total number of samples._<br/><br/>

- _Batch Size & Maximum Number of Learning Iterations_ <br/>

  - _In this experiment, the batch size is 128, and the model is trained by iterating up to a maximum of 100 times._<br/>
  
  - _The number of batch size and iterations during training affects the speed and accuracy of the model, and I, as the researcher conducting the experiment, have set the number of batch size and iterations based on my experience of tuning deep learning models._<br/><br/> <br/> 

### 3. &nbsp; Data Preprocessing and Analysis <br/><br/>

- _**Package Settings**_ <br/> 
  
  ```
  from sklearn.datasets import load_wine
  from sklearn.model_selection import train_test_split
  from sklearn.preprocessing import MinMaxScaler, StandardScaler

  from keras import initializers
  from keras.utils import np_utils
  from keras.optimizers import Adam
  from keras.models import Sequential
  from keras.layers import Flatten, Dense, Dropout

  import random
  import numpy as np
  import pandas as pd
  import seaborn as sns
  import matplotlib.pyplot as plt
  ```

- _**Data Preparation**_ <br/> 
  
  ```
  # ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
  data = load_wine(as_frame = True)

  # ë°ì´í„° ì„¸íŠ¸ ê°œìš” : ê° ì—´ë³„ ìµœëŒ€ ë° ìµœì†Œ ë¶„í¬ë¥¼ íŒŒì•…
  print(data.DESCR)
  ```
  
  ```
  # ì…ë ¥ ë°ì´í„°ì™€ ë¼ë²¨ ë°ì´í„°ë¥¼ ì¶œë ¥í•¨ìœ¼ë¡œì¨ ê°œëµì ì¸ ìˆ˜ì¹˜ë¥¼ í™•ì¸ 
  x_df = data['data']
  y_df = pd.DataFrame(data['target'], columns=['target'])
  all_data_df = pd.concat([x_df, y_df], axis=1)
  all_data_df
  ```
  
  ```
  # ë°ì´í„° í”„ë ˆì„ì˜ íŠ¹ì„±(feature) ì´ë¦„ê³¼ ëª©í‘œ ë³€ìˆ˜(target) ì´ë¦„ ì¶œë ¥
  print("[ ë°ì´í„° í”„ë ˆì„ì˜ íŠ¹ì„±(feature) ]")
  print("\n".join(f" - {feature}" for feature in data.feature_names))

  # ëª©í‘œ ë³€ìˆ˜ì—ì„œ ìˆœì„œëŒ€ë¡œ 'class_0'ëŠ” 0, 'class_1'ì€ 1, 'class_2'ì€ 2ì„ ì˜ë¯¸
  print("\n[ ë°ì´í„° í”„ë ˆì„ì˜ ëª©í‘œ ë³€ìˆ˜(target) ]")
  print("\n".join(f" - {target}" for target in data.target_names))
  ```
  
  ```
  # data ë¶€ë¶„ì„ 8:1:1 ë¹„ìœ¨ë¡œ í•™ìŠµìš©ê³¼ ê²€ì¦ìš©, í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ì…‹ìœ¼ë¡œ ë¶„ë¦¬
  x_train, x_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=723)
  x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.5, random_state=723)
  ```
  
- _**Exploratory Data Analysis (EDA)**_ <br/> 
  
  ```
  # ì´ìƒì¹˜ ì œê±° í•¨ìˆ˜ ì •ì˜
  def remove_outliers_iqr(df, threshold=1.5):
      columns = df.columns
      for column in columns:
          q1 = df[column].quantile(0.25)
          q3 = df[column].quantile(0.75)
          iqr = q3 - q1
          lower_bound = q1 - threshold * iqr
          upper_bound = q3 + threshold * iqr
          df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]
      return df

  # ì´ìƒì¹˜ ì œê±° ë° ë¹„ìœ¨ ê³„ì‚°
  filtered_x_train = remove_outliers_iqr(x_train)
  filtered_y_train = y_train[filtered_x_train.index]
  outlier_ratio = (len(x_train) - len(filtered_x_train)) / len(x_train) * 100

  # ê²°ê³¼ ì¶œë ¥
  print("ì´ìƒì¹˜ ì œê±° ì „ ë°ì´í„°í”„ë ˆì„ í¬ê¸°:", x_train.shape)
  print("ì´ìƒì¹˜ ì œê±° í›„ ë°ì´í„°í”„ë ˆì„ í¬ê¸°:", filtered_x_train.shape)
  print("ì´ìƒì¹˜ ë¹„ìœ¨: {:.2f}%".format(outlier_ratio))
  ```
  
  ```
  # ë°ì´í„° ì‹œê°í™”ë¥¼ ìœ„í•´ í‘œì¤€í™”
  std_1 = StandardScaler()
  x_train_std= std_1.fit_transform(x_train)
  std_2 = StandardScaler()
  filtered_x_train_std = std_2.fit_transform(filtered_x_train)

  # ê·¸ë˜í”„ í¬ê¸° ë° ìŠ¤íƒ€ì¼, í°íŠ¸ ì„¤ì •
  plt.figure(figsize=(14, 4), dpi=100)
  plt.style.use('seaborn-darkgrid')
  plt.rcParams.update({'font.size': 12})

  # ê·¸ë˜í”„ íƒ€ì´í‹€, ì¶• ë ˆì´ë¸” ë° ë²”ìœ„ ì„¤ì •
  plt.subplot(1, 2, 1)
  sns.boxplot(data=x_train_std, palette='Set3')
  plt.title("Box Plot of Scaled Features", fontsize=14)
  plt.xlabel("Features", fontsize=10)
  plt.ylabel("Scaled Values", fontsize=10)
  plt.ylim(-4, 4)

  plt.subplot(1, 2, 2)
  sns.boxplot(data=filtered_x_train_std, palette='Set3')
  plt.title(f"\nBox Plot of Scaled Features (Outliers Removed)", fontsize=14)
  plt.xlabel("Features", fontsize=10)
  plt.ylabel("Scaled Values", fontsize=10)
  plt.ylim(-4, 4)  

  plt.tight_layout()

  plt.show()
  ```
  
  <img src="https://github.com/qortmdgh4141/Comparing-the-Effect-of-Feature-Scaling-on-MLP-for-Classification-Problem/blob/main/image/boxplot_graph.png?raw=true">
    
- _**Feature Scaling**_ <br/>  
  
  ```
  x_train = filtered_x_train
  y_train = filtered_y_train

  # í”¼ì²˜ ìŠ¤ì¼€ì¼ë§ : ìµœì†Œ-ìµœëŒ€ ì •ê·œí™” 
  mm = MinMaxScaler()
  x_train_mm = mm.fit_transform(x_train)
  x_val_mm = mm.fit_transform(x_val)
  x_test_mm = mm.fit_transform(x_test)

  # í”¼ì²˜ ìŠ¤ì¼€ì¼ë§ : í‘œì¤€í™”
  std = StandardScaler()
  x_train_std = std.fit_transform(x_train)
  x_val_std = std.fit_transform(x_val)
  x_test_std = std.fit_transform(x_test)

  # ë¼ë²¨ ë°ì´í„°ì˜ ì›-í•« ì¸ì½”ë”©
  y_train = np_utils.to_categorical(y_train)
  y_val = np_utils.to_categorical(y_val)
  y_test = np_utils.to_categorical(y_test)
  ```

### 4. &nbsp; Training and Testing MLP Model <br/><br/>

- _Optimized MLP Model_

  ```
  """
  1. ì™„ì „ì—°ê²° ê³„ì¸µ (Dense Layer)
      - ë…¸ë“œ ìˆ˜: 256 or 3
      - ì™„ì „ì—°ê²° ê³„ì¸µì€ ëª¨ë“  ì…ë ¥ê³¼ ì¶œë ¥ì„ ì—°ê²°í•˜ëŠ” ì „í†µì ì¸ ì‹ ê²½ë§ ê³„ì¸µ
      - ì¶”ìƒì ì¸ íŠ¹ì§•ì„ í•™ìŠµí•˜ê³ , ë‹¤ì–‘í•œ í´ë˜ìŠ¤ì— ëŒ€í•œ í™•ë¥  ë¶„í¬ë¥¼ ì¶œë ¥í•˜ëŠ” ì—­í• ì„ ìˆ˜í–‰

  2. ë“œë¡­ì•„ì›ƒ(Dropout) ì¸µ
      - ì‹ ê²½ë§ì˜ í•™ìŠµ ê³¼ì •ì—ì„œ ê³¼ì í•©ì„ ì¤„ì´ê¸° ìœ„í•´ ì‚¬ìš©ë˜ëŠ” ì •ê·œí™” ê¸°ë²•ì¸ ë“œë¡­ì•„ì›ƒ(Dropout) ì¸µì„ ì¶”ê°€
      - ë“œë¡­ì•„ì›ƒì€ í•™ìŠµ ê³¼ì • ì¤‘ì— ì‹ ê²½ë§ì˜ ì¼ë¶€ ìœ ë‹›(neuron)ì„ ì„ì˜ë¡œ ì„ íƒí•˜ì—¬ ë¹„í™œì„±í™”ì‹œí‚´ìœ¼ë¡œì¨,
        ëª¨ë¸ì´ íŠ¹ì • ìœ ë‹›ì— ê³¼ë„í•˜ê²Œ ì˜ì¡´í•˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ê±° ì¼ë°˜í™” ëŠ¥ë ¥ì„ í–¥ìƒ

  3. ì€ë‹‰ì¸µì˜ í™œì„±í™” í•¨ìˆ˜ :  Relu
     - ì…ë ¥ê°’ì´ 0ë³´ë‹¤ ì‘ì„ ê²½ìš°ëŠ” 0ìœ¼ë¡œ ì¶œë ¥í•˜ê³ , 0ë³´ë‹¤ í° ê²½ìš°ëŠ” ê·¸ëŒ€ë¡œ ì¶œë ¥í•˜ëŠ” ë¹„ì„ í˜• í•¨ìˆ˜ì¸ Relu í•¨ìˆ˜ë¡œ ì„¤ì •
     - ReLU í™œì„±í™” í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ë•Œ, ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”ì— ë”°ë¥¸ ê·¸ë˜ë””ì–¸íŠ¸ ì†Œì‹¤ ë¬¸ì œë¥¼ ì™„í™”í•˜ê¸° ìœ„í•´ ì€ë‹‰ì¸µì˜ ê°€ì¤‘ì¹˜ëŠ” He ì´ˆê¹ƒê°’ì„ ì‚¬ìš©

  4. ì¶œë ¥ì¸µì˜ í™œì„±í™” í•¨ìˆ˜ :  Softmax
     - ì£¼ë¡œ ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ ë¬¸ì œì—ì„œ ì¶œë ¥ì¸µì—ì„œ ì‚¬ìš©ë˜ëŠ” í™œì„±í™” í•¨ìˆ˜ì¸  Softmaxë¡œ ì„¤ì •
     - Softmax í•¨ìˆ˜ëŠ” ì…ë ¥ë°›ì€ ê°’ì„ ì •ê·œí™”í•˜ì—¬ ê° í´ë˜ìŠ¤ì— ì†í•  í™•ë¥ ì„ ê³„ì‚°í•˜ë©°, ëª¨ë“  í´ë˜ìŠ¤ì— ëŒ€í•œ í™•ë¥ ì˜ í•©ì€ 1

  5. ìµœì í™” ì•Œê³ ë¦¬ì¦˜ : Adam
     - Momentumê³¼ RMSPropì˜ ì¥ì ì„ ê²°í•©í•œ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ì¸ Adam(Adaptive Moment Estimation)ì„ ì‚¬ìš©
     - Momentumì€ : ê¸°ìš¸ê¸°ì˜ ë°©í–¥ì„ ê³ ë ¤í•˜ì—¬ í•™ìŠµ ì†ë„ë¥¼ ì¡°ì ˆ 
     - RMSProp : ê¸°ìš¸ê¸° í¬ê¸°ë¥¼ ê³ ë ¤í•˜ì—¬ í•™ìŠµ ì†ë„ë¥¼ ì¡°ì ˆ

  6. ì†ì‹¤ í•¨ìˆ˜ : Cross-Entropy Loss Function
     - ì¶œë ¥ì¸µì—ì„œ Softmax í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ê²½ìš°, ì†ì‹¤ í•¨ìˆ˜ë¡œëŠ” ì£¼ë¡œ í¬ë¡œìŠ¤ ì—”íŠ¸ë¡œí”¼ ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì‚¬ìš©
     - í¬ë¡œìŠ¤ ì—”íŠ¸ë¡œí”¼ ì†ì‹¤ í•¨ìˆ˜(Cross-Entropy Loss Function)ëŠ” ì‹¤ì œ íƒ€ê¹ƒ ê°’ì— í•´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤ì— ëŒ€í•´ì„œë§Œ ì˜¤ì°¨ë¥¼ ê³„ì‚°í•˜ë©°, 
       ì˜¤ì°¨ë¥¼ ìµœì†Œí™”í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ í•™ìŠµì´ ì§„í–‰

  7. ì •í™•ë„ í‰ê°€ ì§€í‘œ : Accuracy
     - ë¶„ë¥˜ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ì§€í‘œ ì¤‘ í•˜ë‚˜ì¸ Accuracyë¥¼ ì‚¬ìš©
     - ì˜ˆì¸¡í•œ í´ë˜ìŠ¤ê°€ ì‹¤ì œ íƒ€ê¹ƒ í´ë˜ìŠ¤ì™€ ì¼ì¹˜í•˜ëŠ” ê²½ìš°ë¥¼ ì •í™•í•œ ë¶„ë¥˜ë¡œ ê°„ì£¼í•˜ê³ , ì´ë¥¼ ì „ì²´ ìƒ˜í”Œ ìˆ˜ë¡œ ë‚˜ëˆ„ì–´ ì •í™•ë„ë¥¼ ê³„ì‚°

  8. ë°°ì¹˜ ì‚¬ì´ì¦ˆ / í•™ìŠµ ë°˜ë³µ íšŸìˆ˜ / í•™ìŠµë¥  : 128 / 100 / 0.001
  """
  # ëª¨í˜• êµ¬ì¡°  
  model = Sequential()
  model.add(Flatten(input_shape=(13,)))
  model.add(Dropout(0.25))
  model.add(Dense(256, activation='relu', kernel_initializer=initializers.HeNormal()))
  model.add(Dense(3, activation='softmax'))

  model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy']) 

  model.summary() # ëª¨í˜• êµ¬ì¡° ì¶œë ¥ 
  ```

  ```
  # í•™ìŠµ
  results_mm = model.fit(x_train_mm, y_train, validation_data=(x_val_mm, y_val), epochs=100, batch_size=128)
  ```
    
  ```
  # í•™ìŠµëœ ëª¨í˜• í…ŒìŠ¤íŠ¸ 
  score_mm = model.evaluate(x_test_mm, y_test)
  accuracy_mm = round(score_mm[1]*100, 2)
  print(f"ì •ê·œí™” ê¸°ë°˜ MLP ëª¨ë¸ì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ ì†ì‹¤í•¨ìˆ˜ ê°’ : {round(score_mm[0], 2)}")
  print(f"ì •ê·œí™” ê¸°ë°˜ MLP ëª¨ë¸ì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ ì •í™•ë„      : {accuracy_mm}%")
  ```
  
  ```
  # í•™ìŠµëœ ëª¨í˜•ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì˜ˆì¸¡
  y_pred_mm = model.predict(x_test_mm)

  # ì˜ˆì¸¡ ê°’ê³¼ ì‹¤ì œ ê°’ì˜ ë¼ë²¨
  y_pred_class_mm = np.argmax(y_pred_mm, axis=1)
  y_test_class = np.argmax(y_test, axis=1)

  # êµì°¨í‘œ : ì‹¤ì œ ê°’ ëŒ€ë¹„ ì˜ˆì¸¡ ê°’ (ì£¼ëŒ€ê°ì›ì†Œì˜ ê°’ì´ ì •í™•í•˜ê²Œ ë¶„ë¥˜ëœ ë¹ˆë„, ê·¸ ì™¸ëŠ” ì˜¤ë¶„ë¥˜ ë¹ˆë„)
  crosstab_mm = pd.crosstab(y_test_class ,y_pred_class_mm)
  crosstab_mm
  ```
  
  ```
  # í•™ìŠµ
  results_std = model.fit(x_train_std, y_train, validation_data=(x_val_std, y_val), epochs=100, batch_size=128)
  ```
  
  ```
  # í•™ìŠµëœ ëª¨í˜• í…ŒìŠ¤íŠ¸ 
  score_std = model.evaluate(x_test_std, y_test)
  accuracy_std = round(score_std[1]*100, 2)
  print(f"í‘œì¤€í™” ê¸°ë°˜ MLP ëª¨ë¸ì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ ì†ì‹¤í•¨ìˆ˜ ê°’ : {round(score_std[0], 2)}")
  print(f"í‘œì¤€í™” ê¸°ë°˜ MLP ëª¨ë¸ì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ ì •í™•ë„      : {accuracy_std}%"))
  ```
  
  ```
  # í•™ìŠµëœ ëª¨í˜•ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì˜ˆì¸¡
  y_pred_std = model.predict(x_test_std)

  # ì˜ˆì¸¡ ê°’ê³¼ ì‹¤ì œ ê°’ì˜ ë¼ë²¨
  y_pred_class_std = np.argmax(y_pred_std, axis=1)
  y_test_class = np.argmax(y_test, axis=1)

  # êµì°¨í‘œ : ì‹¤ì œ ê°’ ëŒ€ë¹„ ì˜ˆì¸¡ ê°’ (ì£¼ëŒ€ê°ì›ì†Œì˜ ê°’ì´ ì •í™•í•˜ê²Œ ë¶„ë¥˜ëœ ë¹ˆë„, ê·¸ ì™¸ëŠ” ì˜¤ë¶„ë¥˜ ë¹ˆë„)
  crosstab_std = pd.crosstab(y_test_class ,y_pred_class_std)
  crosstab_std
  ```
  <br/> 
    
### 5. &nbsp; Research Results  <br/><br/>
    
- _In this study, I performed IQR-based outlier detection and removal on the 'Wine Recognition Dataset' from the UCI Machine Learning Repository, which contains outliers, and trained MLP models with the same structure using two datasets with normalization and standardization._ <br/> 

- _The graph below illustrates the changes in loss and accuaracy as the number of epochs increases during the training process of the MLP models._ <br/> <br/> 
  
  ```
  def plot_loss_and_accuracy(train_loss, val_loss, train_acc, val_acc, model_name):
      epochs = range(1, len(train_loss) + 1)

      plt.figure(figsize=(14, 6))

      # Loss ë° Accuracy ê·¸ë˜í”„
      plt.subplot(2, 2, 1)
      plt.plot(epochs, train_loss, 'b', label='Training Loss')
      plt.plot(epochs, val_loss, 'r', label='Validation Loss')
      plt.title(f'{model_name}-based MLP - Training and Validation Loss', fontsize=13)
      plt.xlabel('Epoch')
      plt.ylabel('Loss')
      plt.ylim(0, 1.7)
      plt.legend()

      plt.subplot(2, 2, 2)
      plt.plot(epochs, train_acc, 'b', label='Training Accuracy')
      plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')
      plt.title(f'{model_name}-based MLP  - Training and Validation Accuracy', fontsize=13)
      plt.xlabel('Epoch')
      plt.ylabel('Accuracy')
      plt.ylim(0, 1.0)
      plt.legend()

      plt.tight_layout()

      plt.show()

  # ê·¸ë˜í”„ ì¶œë ¥
  plot_loss_and_accuracy(results_mm.history['loss'], results_mm.history['val_loss'],
                         results_mm.history['accuracy'], results_mm.history['val_accuracy'], 'Normalization')
  plot_loss_and_accuracy(results_std.history['loss'], results_std.history['val_loss'],
                         results_std.history['accuracy'], results_std.history['val_accuracy'], 'Standardization')
  ```
  
  <img src="https://github.com/qortmdgh4141/Comparing-the-Effect-of-Feature-Scaling-on-MLP-for-Classification-Problem/blob/main/image/line_graph.png?raw=true">

- _As shown in the graph, the MLP model trained with normalization suffered from underfitting during the training process. Underfitting occurs when the model fails to sufficiently train from the training data, leading to an inadequate understanding of the relationship between the training data and new input data._ <br/>
 
- _On the other hand, the MLP model trained with standardization shows rapid convergence of the loss to the optimal value as the number of epochs increases. Moreover, the decreasing Loss for both the training and validation data suggests that the model has high generalization ability._ <br/>
  
- _Furthermore, examining the changes in accuracy for the training and validation datasets, the MLP model trained with standardization demonstrates a gradual increase in accuracy. However, the model trained with normalization maintains a low accuracy due to underfitting._ <br/><br/>

  ```
  def gradientbars(bars, cmap_list):
      grad = np.atleast_2d(np.linspace(0, 1, 256)).T
      ax = bars[0].axes
      lim = ax.get_xlim() + ax.get_ylim()
      ax.axis(lim)
      max_width = max([bar.get_width() for bar in bars])
      for i, bar in enumerate(bars):
          bar.set_facecolor("none")
          x, y = bar.get_xy()
          w, h = bar.get_width(), bar.get_height()
          ax.imshow(grad, extent=[x, x + w, y, y + h], aspect="auto", cmap=cmap_list[i])
          plt.text(w + 0.7, y + h / 2.0 + 0.015, "{}%".format(int(w)), fontsize=12, ha='left', va='center')

  acc = [accuracy_mm, accuracy_std]

  models = ['Normalization', 'Standardization']
  cmap_list = ['Reds', 'Blues']

  fig, ax = plt.subplots(figsize=(12, 4))
  bars = ax.barh(models, acc, color='white', alpha=0.7)
  gradientbars(bars, cmap_list)

  ax.set_ylabel('Feature Scaling Method\n', fontsize=14)
  ax.set_xlabel('Accuracy', fontsize=14)
  ax.set_title('< Accuracy Comparison : Standardization vs Normalization >\n', fontsize=14)

  plt.show()
  ```
  
  <img src="https://github.com/qortmdgh4141/Comparing-the-Effect-of-Feature-Scaling-on-MLP-for-Classification-Problem/blob/main/image/bar_graph.png?raw=true">
  
- _Lastly, the graph below illustrates the accuracy of the MLP models trained with normalization and standardization when applied to the test dataset. The model trained with standardization has a high accuracy of about 94%, which can be considered a strong classification model. However, the accuracy of the model trained with normalization is about 33%, suggesting that it is not performing well in terms of classification._ <br/>
 
- _In conclusion, the performance difference between the two models is very large, about 3 times, indicating that the feature scaling technique has a very significant impact on the performance of the model. Therefore, in future research or practical applications, feature scaling should be considered as an important preprocessing step along with outlier removal, which will make a great contribution to improving model performance._ <br/> <br/> <br/>
 
--------------------------
### ğŸ’» S/W Development Environment
<p>
  <img src="https://img.shields.io/badge/Windows 10-0078D6?style=flat-square&logo=Windows&logoColor=white"/>
  <img src="https://img.shields.io/badge/Google Colab-black?style=flat-square&logo=Google Colab&logoColor=yellow"/>
  <img src="https://img.shields.io/badge/Python-3776AB?style=flat-square&logo=Python&logoColor=white"/>
</p>
<p>
  <img src="https://img.shields.io/badge/Keras-D00000?style=flat-square&logo=keras&logoColor=white"/>
  <img src="https://img.shields.io/badge/scikit learn-blue?style=flat-square&logo=scikitlearn&logoColor=F7931E"/>
  <img src="https://img.shields.io/badge/Numpy-013243?style=flat-square&logo=Numpy&logoColor=blue"/>
</p>

### ğŸš€ Machine Learning Model
<p>
  <img src="https://img.shields.io/badge/MLP-5C5543?style=flat-square?"/>
  <img src="https://img.shields.io/badge/CNN-4169E1?style=flat-square?"/>
</p> 

### ğŸ’¾ Datasets used in the project
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Fashion-MNIST Dataset <br/>
